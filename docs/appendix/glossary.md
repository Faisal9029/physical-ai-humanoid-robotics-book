---
sidebar_position: 2
---

# Glossary

This glossary defines key terms used throughout the Physical AI & Humanoid Robotics textbook.

## A

**Actuator**: A component of a robot that converts energy into physical motion or force.

**Artificial Intelligence (AI)**: The simulation of human intelligence in machines programmed to think and learn like humans.

## B

**Behavior Tree**: A hierarchical structure used to organize and control the execution of tasks in robotics and AI systems.

## C

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world.

## D

**Digital Twin**: A virtual representation of a physical object or system that can be used for simulation, analysis, and optimization.

**Distributed System**: A system in which components located on networked computers communicate and coordinate their actions by passing messages.

## E

**Embodied AI**: Artificial intelligence that is integrated with a physical body and interacts with the real world.

## F

**Forward Kinematics**: The use of joint angles to determine the position and orientation of the end effector of a robotic arm.

## G

**Gazebo**: An open-source 3D robotics simulator that provides accurate physics simulation and rendering.

## H

**Humanoid Robot**: A robot with human-like characteristics and form, designed to interact with human environments.

## I

**Inverse Kinematics**: The mathematical process of determining joint angles required to achieve a desired end-effector position.

**Isaac Sim**: NVIDIA's robotics simulator for developing and testing AI-based robotics applications.

## L

**Locomotion**: The ability to move from one place to another, particularly in the context of legged robots.

## M

**Middleware**: Software that provides common services and capabilities to applications beyond what's offered by the operating system.

## N

**Navigation Stack (Nav2)**: A collection of ROS 2 packages that provide path planning, obstacle avoidance, and localization capabilities.

## P

**Perception**: The process by which robots interpret sensory information to understand their environment.

**Physical AI**: The field that combines artificial intelligence with physical systems to create intelligent machines that interact with the physical world.

## R

**ROS 2 (Robot Operating System 2)**: A flexible framework for writing robot software that provides hardware abstraction, device drivers, and message passing.

**RT (Real-time)**: Systems that must respond to inputs within strict time constraints to ensure correct operation.

## S

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Simulation**: The imitation of the operation of a real-world process or system over time.

## T

**Transform (TF2)**: The ROS 2 package that provides a framework for tracking coordinate frames in a distributed system.

## U

**URDF (Unified Robot Description Format)**: An XML format for representing a robot model in ROS.

## V

**Vision-Language-Action (VLA)**: Systems that integrate visual perception, language understanding, and physical action capabilities.

## W

**Whisper**: An automatic speech recognition system developed by OpenAI that converts speech to text.